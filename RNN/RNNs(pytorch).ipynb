{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1918597-bdd8-4e98-b893-ac7413b11cfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 2814k  100 2814k    0     0   504k      0  0:00:05  0:00:05 --:--:--  701k\n",
      "Archive:  data.zip\n",
      "   creating: data/\n",
      "  inflating: data/eng-fra.txt        \n",
      "   creating: data/names/\n",
      "  inflating: data/names/Arabic.txt   \n",
      "  inflating: data/names/Chinese.txt  \n",
      "  inflating: data/names/Czech.txt    \n",
      "  inflating: data/names/Dutch.txt    \n",
      "  inflating: data/names/English.txt  \n",
      "  inflating: data/names/French.txt   \n",
      "  inflating: data/names/German.txt   \n",
      "  inflating: data/names/Greek.txt    \n",
      "  inflating: data/names/Irish.txt    \n",
      "  inflating: data/names/Italian.txt  \n",
      "  inflating: data/names/Japanese.txt  \n",
      "  inflating: data/names/Korean.txt   \n",
      "  inflating: data/names/Polish.txt   \n",
      "  inflating: data/names/Portuguese.txt  \n",
      "  inflating: data/names/Russian.txt  \n",
      "  inflating: data/names/Scottish.txt  \n",
      "  inflating: data/names/Spanish.txt  \n",
      "  inflating: data/names/Vietnamese.txt  \n"
     ]
    }
   ],
   "source": [
    "!curl -O https://download.pytorch.org/tutorial/data.zip; unzip data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1da0785-0718-4539-a32d-cf04f164ba02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from string import ascii_letters\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from unidecode import unidecode\n",
    "\n",
    "_ = torch.manual_seed(42)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d77f2c68-9dc6-4672-ab00-7d74c8060635",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"./data/names\"\n",
    "\n",
    "lang2label = {\n",
    "    file_name.split(\".\")[0]: torch.tensor([i], dtype=torch.long)\n",
    "    for i, file_name in enumerate(os.listdir(data_dir))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa572ed3-d82d-42ac-aaf5-16a70c313ef1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Arabic': tensor([0]),\n",
       " 'Chinese': tensor([1]),\n",
       " 'Czech': tensor([2]),\n",
       " 'Dutch': tensor([3]),\n",
       " 'English': tensor([4]),\n",
       " 'French': tensor([5]),\n",
       " 'German': tensor([6]),\n",
       " 'Greek': tensor([7]),\n",
       " 'Irish': tensor([8]),\n",
       " 'Italian': tensor([9]),\n",
       " 'Japanese': tensor([10]),\n",
       " 'Korean': tensor([11]),\n",
       " 'Polish': tensor([12]),\n",
       " 'Portuguese': tensor([13]),\n",
       " 'Russian': tensor([14]),\n",
       " 'Scottish': tensor([15]),\n",
       " 'Spanish': tensor([16]),\n",
       " 'Vietnamese': tensor([17])}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lang2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b7ae8ac-c659-4fd7-a8c6-cdf5cf6d58a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_langs = len(lang2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c798c83-a134-4ec9-b31f-cbc04c8b7be1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char2idx = {letter: i for i, letter in enumerate(ascii_letters + \" .,:;-\")}\n",
    "num_letters = len(char2idx)\n",
    "num_letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "73a39a16-6e26-4a75-993b-e137b01c833b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def name2tensor(name):\n",
    "    tensor = torch.zeros(len(name), 1, num_letters)\n",
    "    for i, char in enumerate(name):\n",
    "        tensor[i][0][char2idx[char]] = 1\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "017f5d63-d4f1-423b-86f6-a34b2d2862ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name2tensor(\"abc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d2d96cdf-53d3-4d0e-a8d1-a0c342e97504",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_names = []\n",
    "target_langs = []\n",
    "\n",
    "for file in os.listdir(data_dir):\n",
    "    with open(os.path.join(data_dir, file)) as f:\n",
    "        lang = file.split(\".\")[0]\n",
    "        names = [unidecode(line.rstrip()) for line in f]\n",
    "        for name in names:\n",
    "            try:\n",
    "                tensor_names.append(name2tensor(name))\n",
    "                target_langs.append(lang2label[lang])\n",
    "            except KeyError:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d5066ae3-54ef-4fd6-96c7-b9db9d80ec25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prateek/.conda/envs/ml/lib/python3.11/site-packages/sklearn/utils/_array_api.py:380: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  array = numpy.asarray(array, order=order, dtype=dtype)\n",
      "/home/prateek/.conda/envs/ml/lib/python3.11/site-packages/sklearn/utils/_array_api.py:380: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  array = numpy.asarray(array, order=order, dtype=dtype)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_idx, test_idx = train_test_split(\n",
    "    range(len(target_langs)),\n",
    "    test_size = 0.1,\n",
    "    shuffle = True,\n",
    "    stratify = target_langs\n",
    ")\n",
    "\n",
    "train_dataset = [\n",
    "    (tensor_names[i], target_langs[i])\n",
    "    for i in train_idx\n",
    "]\n",
    "\n",
    "test_dataset = [\n",
    "    (tensor_names[i], target_langs[i])\n",
    "    for i in test_idx\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b43cdd73-871d-428c-84a6-ae76666535a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 17984\n",
      "Test: 1999\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train: {len(train_dataset)}\")\n",
    "print(f\"Test: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4e784912-d384-4f2b-9d63-5d6eea987bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(MyRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.in2hidden = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.in2output = nn.Linear(input_size + hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x, hidden_state):\n",
    "        combined = torch.cat((x, hidden_state), 1)\n",
    "        hidden = torch.sigmoid(self.in2hidden(combined))\n",
    "        output = self.in2output(combined)\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self):\n",
    "        return nn.init.kaiming_uniform_(torch.empty(1, self.hidden_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1ff17169-a815-4cf3-ab5b-992aed8cfe0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 256\n",
    "learning_rate = 0.001\n",
    "\n",
    "model = MyRNN(num_letters, hidden_size, num_langs)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6aa1ed98-0a88-4f8c-83b2-a537c22ee450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Step [3000/17984], Loss: 0.0367\n",
      "Epoch [1/2], Step [6000/17984], Loss: 0.0116\n",
      "Epoch [1/2], Step [9000/17984], Loss: 0.0026\n",
      "Epoch [1/2], Step [12000/17984], Loss: 0.0247\n",
      "Epoch [1/2], Step [15000/17984], Loss: 0.0031\n",
      "Epoch [2/2], Step [3000/17984], Loss: 0.1365\n",
      "Epoch [2/2], Step [6000/17984], Loss: 0.6683\n",
      "Epoch [2/2], Step [9000/17984], Loss: 0.0297\n",
      "Epoch [2/2], Step [12000/17984], Loss: 0.0078\n",
      "Epoch [2/2], Step [15000/17984], Loss: 0.3552\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 2\n",
    "print_interval = 3000\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    random.shuffle(train_dataset)\n",
    "    for i, (name, label) in enumerate(train_dataset):\n",
    "        hidden_state = model.init_hidden()\n",
    "        for char in name:\n",
    "            output, hidden_state = model(char, hidden_state)\n",
    "        loss = criterion(output, label)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), 1)\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i + 1) % print_interval == 0:\n",
    "            print(\n",
    "                f\"Epoch [{epoch + 1}/{num_epochs}], \"\n",
    "                f\"Step [{i + 1}/{len(train_dataset)}], \"\n",
    "                f\"Loss: {loss.item():.4f}\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bffe56da-e016-4f46-9301-3443ccca4a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 72.4862%\n"
     ]
    }
   ],
   "source": [
    "num_correct = 0\n",
    "num_samples = len(test_dataset)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for name, label in test_dataset:\n",
    "        hidden_state = model.init_hidden()\n",
    "        for char in name:\n",
    "            output, hidden_state = model(char, hidden_state)\n",
    "        _, pred = torch.max(output, dim=1)\n",
    "        num_correct += bool(pred == label)\n",
    "\n",
    "print(f\"Accuracy: {num_correct / num_samples * 100:.4f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f47e7b9e-7b1f-475a-91f4-c0c234affe57",
   "metadata": {},
   "outputs": [],
   "source": [
    "label2lang = {label.item(): lang for lang, label in lang2label.items()}\n",
    "\n",
    "def myrnn_predict(name):\n",
    "    model.eval()\n",
    "    tensor_name = name2tensor(name)\n",
    "    with torch.no_grad():\n",
    "        hidden_state = model.init_hidden()\n",
    "        for char in tensor_name:\n",
    "            output, hidden_state = model(char, hidden_state)\n",
    "        _, pred = torch.max(output, dim=1)\n",
    "    model.train()    \n",
    "    return label2lang[pred.item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5e36033e-5725-440a-aab5-e67c186bb3ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Russian'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myrnn_predict(\"Slaveya\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "461c6330-bcf0-477c-9ad3-78e2ddd877dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUModel(nn.Module):\n",
    "    def __init__(self, num_layers, hidden_size):\n",
    "        super(GRUModel, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.gru = nn.GRU(\n",
    "            input_size=num_letters, \n",
    "            hidden_size=hidden_size, \n",
    "            num_layers=num_layers,\n",
    "        )\n",
    "        self.fc = nn.Linear(hidden_size, num_langs)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        hidden_state = self.init_hidden()\n",
    "        output, hidden_state = self.gru(x, hidden_state)\n",
    "        output = self.fc(output[-1])\n",
    "        return output\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        return torch.zeros(self.num_layers, 1, self.hidden_size).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "48c5a7c9-624c-411d-ac22-1a3a3d1b3855",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GRUModel(num_layers=2, hidden_size=hidden_size)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7a589d58-7097-4a50-9c2a-c9c410edccff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Step [3000/17984], Loss: 0.1441\n",
      "Epoch [1/2], Step [6000/17984], Loss: 0.2437\n",
      "Epoch [1/2], Step [9000/17984], Loss: 0.8019\n",
      "Epoch [1/2], Step [12000/17984], Loss: 0.0064\n",
      "Epoch [1/2], Step [15000/17984], Loss: 0.6626\n",
      "Epoch [2/2], Step [3000/17984], Loss: 0.0003\n",
      "Epoch [2/2], Step [6000/17984], Loss: 0.0017\n",
      "Epoch [2/2], Step [9000/17984], Loss: 0.6608\n",
      "Epoch [2/2], Step [12000/17984], Loss: 0.0110\n",
      "Epoch [2/2], Step [15000/17984], Loss: 0.3656\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    random.shuffle(train_dataset)\n",
    "    for i, (name, label) in enumerate(train_dataset):\n",
    "        output = model(name)\n",
    "        loss = criterion(output, label)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "         \n",
    "        if (i + 1) % print_interval == 0:\n",
    "            print(\n",
    "                f\"Epoch [{epoch + 1}/{num_epochs}], \"\n",
    "                f\"Step [{i + 1}/{len(train_dataset)}], \"\n",
    "                f\"Loss: {loss.item():.4f}\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e7f3be1f-80d8-4f15-b0de-5babe1030ec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 82.8414%\n"
     ]
    }
   ],
   "source": [
    "num_correct = 0\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for name, label in test_dataset:\n",
    "        output = model(name)\n",
    "        _, pred = torch.max(output, dim=1)\n",
    "        num_correct += bool(pred == label)\n",
    "\n",
    "print(f\"Accuracy: {num_correct / num_samples * 100:.4f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f3affd65-7e2d-4712-9265-a7202828d6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pytorch_predict(name):\n",
    "    model.eval()\n",
    "    tensor_name = name2tensor(name)\n",
    "    with torch.no_grad():\n",
    "        output = model(tensor_name)\n",
    "        _, pred = torch.max(output, dim=1)\n",
    "    model.train()\n",
    "    return label2lang[pred.item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d68985f3-1db0-4ab3-9dd0-c7e277aaf0cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'English'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pytorch_predict(\"Jake\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a89cc7e-b849-471e-ac22-38e3623eb99d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
